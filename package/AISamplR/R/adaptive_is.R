importance_sampling <-
  function(logposterior,
           mu_chains,
           sigma2,
           compute_logdenom = compute_logdenom_byrow,
           T = 100, N = 2, M = 2)
  {
    D = dim(mu_chains)[1]
    xs_chain <-
      gen_xs_rcpp(mu = mu_chains, sigma2 = sigma2,
                  D = D, T = T, N = N, M = M)
    loglik_table <-
      compute_loglik_table(logposterior = logposterior,
                           x = xs_chain,
                           D = D, T = T, N = N, M = M)
    message("Computing denominator table:")
    logdenom_table <-
      compute_logdenom(x = xs_chain,
                         mu = mu_chains,
                         sigma2 = sigma2,
                         D = D, T = T, N = N, M = M)
    weight_table <-
      compute_weight_table(loglik_table = loglik_table,
                           logdenom_table = logdenom_table)
    is_res <- list("x" = xs_chain,
                   "loglik" = loglik_table,
                   "logdenom" = logdenom_table,
                   "weight" = weight_table)
    return(is_res)
  }

create_adaptive_is <- function(gen_mu_chains){
  ais <- function(logposterior,
                  mu, sig2_adapt = sig2_samp, sig2_samp,
                  compute_logdenom = compute_logdenom_byrow,
                  N = 10, T = 100, M = 2)
  {
    mu_chains <-
      gen_mu_chains(logposterior = logposterior,
                               mu = mu, sigma = sig2_adapt,
                               T = T, N = N, M = M)
    is_step <- 
      importance_sampling(logposterior = logposterior,
                          mu_chains = mu_chains,
                          sigma2 = sig2_samp,
                          compute_logdenom = compute_logdenom,
                          T = T, N = N, M = M)
    ais_res <- c(list("mu" = mu_chains), is_step)
    return(ais_res)
  }
}

#' @rdname lais
#' @export
pmc <- create_adaptive_is(gen_mu_chains_pmc)

#' @rdname lais
#' @export
apis <- create_adaptive_is(gen_mu_chains_apis)


#' Adaptive Importance Sampling (LAIS, APIS, PMC).
#'
#' \code{lais}, \code{apis} and \code{pmc} respectively return samples
#'  and the associated weights
#'  generated by the methods LAIS, APIS and PMC.
#'
#' These functions perform adaptive important sampling.
#' They are the implementation of 3 methods:
#' Layered Adaptive Importance Sampling (LAIS),
#' Adaptive Population Importance Sampling (APIS)
#' and Population Monte Carlo (PMC).
#' Theses 3 implementations follows the same steps:
#' \enumerate{
#'   \item the adaptation step where a set of N proposal distributions
#'    are update at each iteration t for t = 1,..., T.
#'   \item the sampling step where M samples are drawn for each of the T x N proposals.
#'   \item the weighting step where all T x N x M samples are given a weight.
#' }
#' 
#' In these 3 implementations, the proposal distributions are
#' multivariate gaussian distributions with independent marginals. 
#' The covariance matrix of theses proposal distribution are all equal
#' and provided by the user through the argument \code{sig2_samp}. 
#' The location parameters of the proposal distributions are initialized by the user
#' and are then updated at each iteration t of the adaptation step. 
#' The three methods implemented here only differ by the way
#' the location parameters mu_\{t, n\} of the proposals are updated.
#' \itemize{
#'   \item \code{lais} uses Markov chain Monte Carlo
#'   with the Metropolis-Hasting algorithm. 
#'   \item \code{apis} draws M samples from the gaussian proposal distribution
#'   with location parameter mu_\{t-1,n\} and then randomly select
#'   1 of the M samples as the new location parameter mu_\{t-,n\}.   
#'   Each sample has a different probability of being chosen.
#'   This probability depends on the weight given by importance sampling
#'   when performed only with this proposal distribution.
#'   \item \code{apis} draws M samples from the gaussian proposal distribution
#'   with location parameter mu_\{t-1,n\} and then takes 
#'   the weighted mean of M samples as the new location parameter mu_\{t,n\}.
#'   The weight of each sample is given by important sampling
#'   when performed only with this proposal distribution.
#' }
#' 
#' The weighting step can be performed in different way depending on
#' how we considered the samples drawn at the sampling step.
#' We can think that one sample was drawn from its own corresponding proposal distribution 
#' or that one sample was drawn from a mixture of proposal distributions. 
#' In this package, three methods to compute the denominator of the weights are available:
#' \itemize{
#'   \item \code{\link{compute_logdenom_bybox}} 
#'   where we considered that on sample x_\{t,n,m\} 
#'   is drawn from an unique 
#'   proposal distribution with location parameter mu_\{t,n\}.
#'   \item \code{\link{compute_logdenom_byrow}}
#'    where we considered that on sample  x_\{t,n,m\} 
#'   is drawn from an equiprobable mixture
#'   of all proposal distributions at time t.
#'   \item \code{\link{compute_logdenom_bytable}}
#'    where we considered that on sample x_\{t,n,m\} 
#'   is drawn from an equiprobable mixture
#'   of all available proposal distributions,
#'   for all times t from 1 to T and 
#'   for the N chains of proposal distribution.
##' }
#' 
#' @param logposterior is either of function or a pointer to a C++ function.
#' Those functions have to take as argument an numerical vector of a given length D.
#' This argument corresponds to the log-likelihood of the posterior distribution,
#' we want to draw samples from.
#' The algorithm used in the adapation step are iterative. 
#' Therefore, this step can be quite slow in R
#'dependening on the \code{logposterior} used. 
#' To improve the computing performance, one can use
#' a C++ function by providing its pointer.
#' To see how such pointers can be created with the package \code{Rcpp},
#' see either the function \code{\link{make_lposterior_rcpp}} or
#' the example below.
#' @param mu A numerical matrix of dimension D x N
#' used to initialized the location parameters of the N chains of proposal distributions.
#' @param sig2_adapt A numerical vector of length D indicating for each dimension
#' the variance of the gaussian proposal distribution used in the adatation step.
#' @param sig2_samp A numerical vector of length D indicating for each dimension
#' the variance of the gaussian proposal distribution used in the sampling step.
#' @param compute_logdenom A function that indicates how to compute denominators
#' for the weights. 
#' @param N An integer indicating the number of chains of proposal distributions
#' that we want to use.
#' @param T An integer indicating the number of iterations used for
#' the adaptation of the N chains of proposal distributions. 
#' It corresponds to the length of the chain of proposal distributions.
#' @param M An integer indicating the numbers of samples
#' to be drawn for each proposal distribution.
#' 
#' @return A list with the following elements. 
#' \itemize{
#'   \item{mu}{an array of dimension D x T x N containing the location parameters of
#'   the poposal distributions used for the importance sampling. 
#'   This location parameters are given by the adaptation step}
#'   \item{x}{an array of dimension T x d x M x N containing the samples
#'   drawn from the proposal distributions in the sampling step.}
#'   \item{loglik}{an array of dimension T x M x N with
#'   the loglikelihood of the posterior distribution 
#'   evaluated for each sample drawn in \code{x}.} 
#'   \item{logdenom}{an array of dimension T x M x N  with logarithm of 
#'   the denominators of the weights for each sample drawn in \code{x}.} 
#'   \item{weight}{an array of dimension T x M x N containing the unormalized weights
#'   associated with the samples in \code{x}.}
##' }
#' @examples
#' # draw samples from the "banana shaped distribution" defined by the loglikelihood lposterior_6.
#' lposterior_6 <- function(x){
#'   x1 <- x[1]
#'   x2 <- x[2]
#'   logtarget <-  -1/32 * (4 - 10 * x1 - x2^2)^2 - x1^2/50 - x2^2/50
#' }
#' 
#' D <- 2
#' T <- 100
#' N <- 50
#' M <- 4
#' 
#' # pmc with an R function for the logposterior
#' pmc_lp6_r <- pmc(lposterior_6,
#'     mu = matrix(rnorm(D*N, sd = 3), nrow = D, ncol = N),
#'     sig2_adapt = rep(1, D), sig2_samp = rep(1, D),
#'     compute_logdenom = compute_logdenom_byrow,
#'     N = N, T = T, M = M)
#' with(pmc_lp6_r, compute_expectation(x, weight)) # theorical value: ~ [-1.09, 0]
#' 
#' # apis with an R function for the logposterior
#' apis_lp6_r <- apis(lposterior_6,
#'     mu = matrix(rnorm(D*N, sd = 3), nrow = D, ncol = N),
#'     sig2_adapt = rep(1, D), sig2_samp = rep(1, D),
#'     compute_logdenom = compute_logdenom_byrow,
#'     N = N, T = T, M = M)
#' with(apis_lp6_r, compute_expectation(x, weight)) # theorical value: ~ [-1.09, 0]
#' 
#' # lais with an R function for the logposterior
#' lais_lp6_r <- lais(lposterior_6,
#'     mu = matrix(rnorm(D * N, sd = 3), nrow = D, ncol = N),
#'     sig2_adapt = rep(1, D), sig2_samp = rep(1, D),
#'     compute_logdenom = compute_logdenom_byrow,
#'     N = N, T = T, M = M)
#' with(lais_lp6_r, compute_expectation(x, weight)) # theorical value: ~ [-1.09, 0]
#' with(lais_lp6_r, rgl_plot(x[1,,,], x[2,,,], exp(loglik)))
#' with(lais_lp6_r, rgl_plot(x[1,,,], x[2,,,], sqrt(weight)))
#'
#' # With C++ code
#' # Create a C++ function and a pointer to the function 
#' # logtarget <-  -1/32 * (4 - 10 * x1 - x2^2)^2 - x1^2/50 - x2^2/50
#'  body_lp6 <- '
#'  // [[Rcpp::export]]
#'  double lposterior(NumericVector x){
#'  double x1 = x[0];
#'  double x2 = x[1];
#'  double logtarget = -1.0/32 * pow(4 - 10 * x1 - pow(x2, 2), 2) - pow(x1, 2)/50 - pow(x2, 2)/50;
#'  return logtarget;
#'  }'
#' lp6 <- make_lposterior_rcpp(body = body_lp6)
#'
#' # lais with an external pointer to an C++ function
#' lais_lp6_rcpp <-  lais(lp6$pointer,
#'     mu = matrix(rnorm(D*N, sd = 3), nrow = D, ncol = N),
#'     sig2_adapt = rep(1, D), sig2_samp = rep(1, D),
#'     compute_logdenom = compute_logdenom_byrow,
#'     N = N, T = T, M = M)
#' with(lais_lp6_rcpp, compute_expectation(x, weight)) # theorical value: ~ [-1.09, 0]
#' with(lais_lp6_rcpp, rgl_plot(x[1,,,], x[2,,,], exp(loglik)))
#' with(lais_lp6_rcpp, rgl_plot(x[1,,,], x[2,,,], sqrt(weight)))
#' 
#' @export
lais <- function(logposterior,
                mu, sig2_adapt = sig2_samp, sig2_samp,
                compute_logdenom = compute_logdenom_byrow,
                T = 100,  N = 2, M = 2)
{
  mu_chains <-
    gen_mu_chains_mcmc(logposterior = logposterior,
                       mu = mu, sigma2 = sig2_adapt,
                       T = T, N = N)
  is_step <- 
    importance_sampling(logposterior = logposterior,
                        mu_chains = mu_chains,
                        sigma2 = sig2_samp,
                        compute_logdenom = compute_logdenom,
                        T = T, N = N, M = M)
  ais_res <- c(list("mu" = mu_chains), is_step)
  invisible(ais_res)
}

